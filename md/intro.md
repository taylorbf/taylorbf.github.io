# Hi, I'm Ben.

I work in the field of [experimental](https://en.wikipedia.org/wiki/Experimental_music) and [electronic music](https://en.wikipedia.org/wiki/Computer_music). Since 2003, I have created music projects in a variety of modes including [internet-based](https://en.wikipedia.org/wiki/Internet_art), [site-specific](https://en.wikipedia.org/wiki/Site-specific_art), networked, and [algorithmic](https://en.wikipedia.org/wiki/Algorithmic_composition). I live in Easthampton, Massachusetts.

From 2007-2017, I researched the use of the internet as a musical instrument. These investigations included the internet as a site for sound installation, the web browser as a performance instrument, and composing using networks. I began by making a series of sound installations on the web while living in Missoula, Montana in 2008. Later that year I began to perform live by opening up dozens of browser tabs to create sound collages.
From 2010 onward, I designed new tools for controlling multi-window media collages in live performance.

This work evolved into participation in the lively web audio community. I lead the development of [NexusUI](https://nexus-js.github.io/ui/), an open-source JavaScript library of HTML5 interface components for web audio projects, and co-authored other open-source toolkits such as [Tune.js](https://github.com/abbernie/tune) and [Gendy.js](https://github.com/abbernie/gendy). In 2016, I helped to organize the [2nd Web Audio Conference](http://webaudio.gatech.edu/) as music & arts co-chair, and more recently I co-wrote a chapter on web audio for the series Foundations of Sound Design.

From 2015-2017, I researched the use of audience mobile devices as a speaker array. My work in this genre included: a [performance](https://vimeo.com/125277975) at Mozilla as part of the first Web Audio Conference; leading a [workshop](https://github.com/taylorbf/distributed-music-workshop) at NIME on designing your own distributed performance; and receiving a grant from [Easthampton City Arts](http://www.easthamptoncityarts.com/) to organize a concert at [Mill 180 Park](https://www.mill180park.com/). My research in this field culminated in compiling an archive of historical work in the genre, published at NIME as [A History of the Audience as a Speaker Array](articles/a-history-of-the-audience-as-a-speaker-array.pdf).

Currently, my creative practice is shifting away from internet-based work and towards compositions of new music in [just intonation](https://en.wikipedia.org/wiki/Just_intonation). These new works explore computational approaches to harmony and form, using creative code and a variety of computer programming tools to organize new musical structures and tuning systems. My work with algorithmic music and live coding has also led to some interesting collaborations, such as in [this](https://vimeo.com/229745504) performance with [EMMI](http://expressivemachines.com/dev/wordpress/) in which I live coded one of their automated zythers, also performed at NIME in Copenhagen.

In addition to my creative work, I have in recent years worked as a designer & developer for several companies and startups including [ReDigi](https://www.google.com/search?q=redigi), a somewhat controversial startup selling used digital music. From 2011-2017 I taught at [Goucher College Digital Arts](http://www.goucher.edu/learn/graduate-programs/mfa-in-art-and-technology/) as an adjunct professor, teaching graduate courses in creative code, internet media art, and web development, and advising Master's thesis projects.
