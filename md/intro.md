# Hi, I'm Ben.

I research computational approaches to media, focusing on internet media and digital sound. Most of the time, I [ write, teach, write about, and compose with ] JavaScript.  Since 2003, I have also worked on creative projects in a variety of modes including [internet-based](https://en.wikipedia.org/wiki/Internet_art), [site-specific](https://en.wikipedia.org/wiki/Site-specific_art), networked, and [algorithmic](https://en.wikipedia.org/wiki/Algorithmic_composition). I live in Hadley, Massachusetts.

Much of my work participates in the lively web audio community. I lead the development of [NexusUI](https://nexus-js.github.io/ui/), an open-source JavaScript library of HTML5 interface components for web audio projects, and I co-author other open-source toolkits such as [Tune.js](https://github.com/abbernie/tune) and [Gendy.js](https://github.com/abbernie/gendy). In 2016, I helped to organize the [2nd Web Audio Conference](http://webaudio.gatech.edu/) as music & arts co-chair, and more recently I co-wrote a chapter on web audio for the series Foundations of Sound Design.

From 2015-2017, I researched the use of audience mobile devices as a speaker array. My work in this genre included: a [performance](https://vimeo.com/125277975) at Mozilla as part of the first Web Audio Conference; leading a [workshop](https://github.com/taylorbf/distributed-music-workshop) at NIME on designing your own distributed performance; and receiving a grant from [Easthampton City Arts](http://www.easthamptoncityarts.com/) to organize a concert at [Mill 180 Park](https://www.mill180park.com/). My research in this field culminated in compiling an archive of historical work in the genre, published at NIME as [A History of the Audience as a Speaker Array](articles/a-history-of-the-audience-as-a-speaker-array.pdf).

Currently, my creative practice is shifting away from internet-based work and towards compositions of new music in [just intonation](https://en.wikipedia.org/wiki/Just_intonation). These new works explore computational approaches to harmony and form, using creative code and a variety of computer programming tools to organize new musical structures and tuning systems. My work with algorithmic music and live coding has also led to some interesting collaborations, such as in [this](https://vimeo.com/229745504) performance with [EMMI](http://expressivemachines.com/dev/wordpress/) in which I live coded one of their automated zythers, also performed at NIME in Copenhagen.

I have in recent years worked as a designer & developer for several companies and startups including [ReDigi](https://www.google.com/search?q=redigi), a controversial startup selling "used digital music." From 2011-2017 I taught at [Goucher College Digital Arts](http://www.goucher.edu/learn/graduate-programs/mfa-in-art-and-technology/) as an adjunct professor, teaching graduate courses in creative code, internet media art, and web development, and advising Master's thesis projects.
